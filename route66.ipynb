{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import common_geo\n",
    "import numpy as np\n",
    "import geocoder\n",
    "import googlemaps\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyCMS_AKA-PwkHFor1rfCLNzxVijWFCB4Lg\n",
      "AIzaSyC92G3JW4JqVgaIWqO1DBFHhjKT2Z52114\n",
      "o91vdIA1eMd4xgoJr9Ah\n",
      "MC-T1SwjT0-ngD5-kiFUiw\n",
      "sk.eyJ1Ijoic2xzdGFybmVzIiwiYSI6ImNpdmg2MWRxdDAweTUyeWxiZ3V3eGp0Mm4ifQ.jmO7REOrlmeW8mkKfrSQHQ\n"
     ]
    }
   ],
   "source": [
    "with open('credentials.yaml') as f: \n",
    "    credentials = yaml.load(f)\n",
    "g_key = credentials['g_key']\n",
    "g_key_tz = credentials['g_key_tz']\n",
    "here_app_id = credentials['here_app_id']\n",
    "here_app_code = credentials['here_app_code']\n",
    "mapbox_token = credentials['mapbox_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key=g_key)\n",
    "gmaps_tz = googlemaps.Client(key=g_key_tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_getter(line, element_name):\n",
    "    start = line.find('<{}>'.format(element_name))\n",
    "    if start > 0:\n",
    "        stop = line.find('</{}>'.format(element_name))\n",
    "        if stop > 0:\n",
    "            start = start + len(element_name) + 2\n",
    "            return line[start:stop]\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coord_conv(s):\n",
    "    return [float(i) for i in s.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def when_conv(s):\n",
    "    try:\n",
    "        return datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    except:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def city_state_grabber(row):\n",
    "    lat = row['Latitude']\n",
    "    lng = row['Longitude']\n",
    "    if row['Row_Num'] % 1000 == 0: print (row['Row_Num'], end=' ')\n",
    "    if row['Speed'] is None or row['Speed'] < 5 or lat is None or lng is None: \n",
    "        return (None, None)\n",
    "    try: \n",
    "        g = geocoder.here([lat, lng], method='reverse', \n",
    "                          app_id = here_app_id, \n",
    "                          app_code = here_app_code)\n",
    "        return (g.city, g.state)\n",
    "    except:\n",
    "        return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kml_file_reader(kml_file):\n",
    "    f = open(kml_file, 'r')\n",
    "    state_flag = 0\n",
    "    timed_position = []\n",
    "    time = None\n",
    "    loc = None\n",
    "    for line in f.readlines():\n",
    "        when = string_getter(line, 'when')\n",
    "        if state_flag == 0 and when:\n",
    "            time = when_conv(when)\n",
    "            state_flag = 1\n",
    "            continue\n",
    "        coord = string_getter(line, 'gx:coord')\n",
    "        if state_flag == 1 and coord:\n",
    "            loc = coord_conv(coord)\n",
    "            timed_position.append([time] + loc)\n",
    "            state_flag = 0\n",
    "            continue\n",
    "    f.close()\n",
    "    return timed_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.exists('full_data.csv'):\n",
    "    trip_data = pd.read_csv('full_data.csv')\n",
    "    trip_data['Date'] = pd.to_datetime(trip_data['Date'])\n",
    "    trip_data = trip_data.set_index(['Date'])\n",
    "    trip_data.index = trip_data.index.tz_localize('UTC')\n",
    "else:\n",
    "    timed_position = kml_file_reader('jhs.kml')\n",
    "    trip_data = pd.DataFrame(timed_position, columns=['Date', 'Longitude', 'Latitude', 'Altitude'])\n",
    "    trip_data = trip_data.sort_values('Date')\n",
    "    trip_data = trip_data.set_index(['Date'])\n",
    "    trip_data.index = trip_data.index.tz_localize('UTC')\n",
    "    trip_data.to_csv('full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: trip start time = 2016-10-27 01:45:13+00:00\n",
    "# NOTE: trip end time = 2016-11-09 18:35:00+00:00\n",
    "trip_data = trip_data[\"2016-Oct-27 01:45\":\"2016-Nov-09 18:35\"]\n",
    "trip_data.to_csv('trip_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1,y1,z1 = common_geo.LLAtoXYZ(trip_data['Latitude'], trip_data['Longitude'], 0)\n",
    "x2 = np.roll(x1,1)\n",
    "y2 = np.roll(y1,1)\n",
    "z2 = np.roll(z1,1)\n",
    "x2[0] = 0\n",
    "y2[0] = 0\n",
    "z2[0] = 0\n",
    "trip_data['Distance'] = np.sqrt((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2)\n",
    "trip_data['Distance'][0] = 0\n",
    "trip_data['Distance'] *= 0.000621371 # converting from meters to miles\n",
    "trip_data['Cumulative Distance'] = trip_data['Distance'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def speed(row):\n",
    "    if (row['Distance'] == 0 or row['Time_Delta'] == 0 \n",
    "        or row['Distance'] is None or row['Time_Delta'] is None):\n",
    "        return None\n",
    "    return row['Distance']/(row['Time_Delta'] / 60 / 60)\n",
    "time = trip_data.index\n",
    "td = [0]\n",
    "for i, t in enumerate(time):\n",
    "    if (i >= 1):\n",
    "        ts = time[i] - time[i-1]\n",
    "        td.append(ts.seconds)\n",
    "trip_data['Time_Delta'] = td\n",
    "trip_data['Speed'] = trip_data.apply(speed, axis=1)\n",
    "trip_data.to_csv('trip_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this did not catch all of the correct breaks...\n",
    "day_of_trip_list = []\n",
    "day_of_trip = 1\n",
    "for row in trip_data.itertuples():\n",
    "    day = row.Index.day\n",
    "    if row.Time_Delta >= (4 * 60 * 60):\n",
    "        day_of_trip += 1\n",
    "    day_of_trip_list.append(day_of_trip)\n",
    "trip_data['Day'] = day_of_trip_list\n",
    "trip_data.to_csv('trip_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day_breaks = ['10/26/16 00:05', '10/27/16 11:03', '10/28/16 11:07', '10/29/16 11:12', \n",
    "              '10/30/16 11:10', '10/31/16 12:07', '11/1/16 11:13',\n",
    "              '11/2/16 13:00', '11/3/16 18:18', '11/4/16 13:51',\n",
    "              '11/5/16 13:45', '11/6/16 11:24', '11/7/16 11:56',\n",
    "              '11/8/16 11:28', '11/9/16 13:30', '11/9/16 23:59']\n",
    "for i in range(len(day_breaks)-1):\n",
    "    trip_data.loc[day_breaks[i]:day_breaks[i+1],'Day'] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip_data_minutes = pd.DataFrame()\n",
    "trip_data_minutes['Longitude'] = trip_data['Longitude'].resample('min').mean()\n",
    "trip_data_minutes['Latitude'] = trip_data['Latitude'].resample('min').mean()\n",
    "trip_data_minutes['Distance'] = trip_data['Distance'].resample('min').sum()\n",
    "trip_data_minutes['Day'] = trip_data['Day'].resample('min').max()\n",
    "trip_data_minutes['Day'].fillna(method='ffill', inplace=True)\n",
    "# trip_data_minutes['Day'] = trip_data_minutes['Day'].astype('int') # doesnt work\n",
    "trip_data_minutes['Time_Delta'] = trip_data['Time_Delta'].resample('min').sum()\n",
    "trip_data_minutes['Speed'] = trip_data_minutes.apply(speed, axis=1)\n",
    "trip_data_minutes['Speed'].fillna(0, inplace=True)\n",
    "trip_data_minutes['Speed_i'] = trip_data_minutes['Speed'].astype('int')\n",
    "trip_data_minutes['Cumulative Distance'] = trip_data_minutes['Distance'].cumsum()\n",
    "trip_data_minutes.to_csv('trip_data_minutes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip_data_stash = trip_data.copy()\n",
    "trip_data_stash.to_csv('trip_data_stash.csv')\n",
    "trip_data = trip_data_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Use to read from trip_data-- minutes and state.csv\n",
    "# get state and city\n",
    "if not ('City' in trip_data and 'State' in trip_data):\n",
    "    cs_data = pd.read_csv('trip_data-- minutes and state.csv')\n",
    "    cs_data['Date'] = pd.to_datetime(cs_data['Date'])\n",
    "    cs_data = cs_data.set_index(['Date'])\n",
    "    cs_data.index = cs_data.index.tz_localize('UTC')\n",
    "    cs_data = cs_data.loc[:,['City', 'State']]\n",
    "    trip_data = trip_data.join(cs_data)\n",
    "    trip_data.to_csv('trip_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Use if you are grabbing anew\n",
    "if not ('City' in trip_data and 'State' in trip_data):\n",
    "    trip_data['Row_Num'] = list(range(len(trip_data)))\n",
    "    c_s = trip_data.apply(city_state_grabber, axis=1)\n",
    "    city, state = zip(*c_s)\n",
    "    trip_data['City'] = list(city)\n",
    "    trip_data['State'] = list(state)\n",
    "    print ('')\n",
    "    del trip_data['Row_Num']\n",
    "    trip_data.to_csv('trip_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not ('Raw Offset' in trip_data and 'DST Offset' in trip_data):\n",
    "    max_dist = trip_data['Cumulative Distance'].max()\n",
    "    split_pt = max_dist / 2300 # 2500 is daily API limit\n",
    "\n",
    "    trip_data['Cumulative_Distance'] = trip_data['Cumulative Distance']\n",
    "    tz_name = []\n",
    "    dst_offset = []\n",
    "    tz_id = []\n",
    "    raw_offset = []\n",
    "    covered_dist = 0\n",
    "    for row in trip_data.itertuples():\n",
    "        if row.Cumulative_Distance - covered_dist >= split_pt:\n",
    "            result = gmaps.timezone((row.Latitude, row.Longitude), \n",
    "                                    int(row.Index.timestamp()))\n",
    "            covered_dist = row.Cumulative_Distance\n",
    "            if result['status'] == 'OK':\n",
    "                tz_name.append(result['timeZoneName'])\n",
    "                dst_offset.append(result['dstOffset'])\n",
    "                tz_id.append(result['timeZoneId'])\n",
    "                raw_offset.append(result['rawOffset'])\n",
    "            else:\n",
    "                tz_name.append(None)\n",
    "                dst_offset.append(None)\n",
    "                tz_id.append(None)\n",
    "                raw_offset.append(None)\n",
    "        else:\n",
    "            tz_name.append(None)\n",
    "            dst_offset.append(None)\n",
    "            tz_id.append(None)\n",
    "            raw_offset.append(None)\n",
    "\n",
    "    trip_data.loc[:, 'Timezone Name'] = tz_name\n",
    "    trip_data.loc[:, 'DST Offset'] = dst_offset\n",
    "    trip_data.loc[:, 'Timezone ID'] = tz_id\n",
    "    trip_data.loc[:, 'Raw Offset'] = raw_offset\n",
    "\n",
    "    del trip_data['Cumulative_Distance']\n",
    "\n",
    "    trip_data.to_csv('trip_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip_data['DST Offset'] = trip_data['DST Offset'].fillna(method='bfill')\n",
    "trip_data['Raw Offset'] = trip_data['Raw Offset'].fillna(method='bfill')\n",
    "trip_data['Local'] = pd.to_datetime(trip_data.index)\n",
    "trip_data['Local'] = trip_data['Local'] + pd.to_timedelta((trip_data['DST Offset'] + \n",
    "                                                           trip_data['Raw Offset']), unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_data_trim = trip_data[trip_data['Time Delta'] < 200]\n",
    "trip_data_trim = trip_data_trim[trip_data_trim['Speed'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_csv = pd.DataFrame()\n",
    "for_csv['Lat'] = trip_data['Latitude'].fillna(method='ffill')\n",
    "for_csv['Long'] = trip_data['Longitude'].fillna(method='ffill')\n",
    "for_csv.to_csv('lat-long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hourly_summary = pd.DataFrame()\n",
    "hourly_summary['Longitude'] = trip_data['Longitude'].resample('H').mean()\n",
    "hourly_summary['Latitude'] = trip_data['Latitude'].resample('H').mean()\n",
    "hourly_summary['Distance'] = trip_data['Distance'].resample('H').sum()\n",
    "hourly_summary['Day'] = trip_data['Day'].resample('H').max()\n",
    "hourly_summary['Day'].fillna(method='ffill', inplace=True)\n",
    "hourly_summary['Time_Delta'] = trip_data['Time_Delta'].resample('H').sum()\n",
    "hourly_summary['Speed'] = hourly_summary.apply(speed, axis=1)\n",
    "hourly_summary['Speed'].fillna(0, inplace=True)\n",
    "hourly_summary['Speed_i'] = hourly_summary['Speed'].astype('int')\n",
    "hourly_summary['Cumulative Distance'] = hourly_summary['Distance'].cumsum()\n",
    "hourly_summary.to_csv('hourly_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Day\n",
       "1.0     167.360155\n",
       "2.0     476.162637\n",
       "3.0     333.056371\n",
       "4.0     297.331604\n",
       "5.0     526.227169\n",
       "6.0     283.581199\n",
       "7.0     410.548355\n",
       "8.0     330.364534\n",
       "9.0     279.858909\n",
       "10.0    176.505005\n",
       "11.0    694.138359\n",
       "12.0    831.010276\n",
       "13.0    619.221463\n",
       "14.0     16.119660\n",
       "15.0    252.663218\n",
       "Name: Distance, dtype: float64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_by_day = pd.pivot_table(trip_data, values='Distance', index=['Day'], aggfunc=np.sum)\n",
    "dist_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukestarnes/anaconda/envs/Py3.5_/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/lukestarnes/anaconda/envs/Py3.5_/lib/python3.5/site-packages/pandas/core/indexing.py:461: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Day\n",
       "1.0     69.992644\n",
       "2.0     62.926742\n",
       "3.0     45.519825\n",
       "4.0     46.461279\n",
       "5.0     52.426822\n",
       "6.0     44.390648\n",
       "7.0     51.901998\n",
       "8.0     45.666785\n",
       "9.0     40.211968\n",
       "10.0    34.587577\n",
       "11.0    75.608869\n",
       "12.0    76.719398\n",
       "13.0    68.775824\n",
       "14.0    33.763115\n",
       "15.0    64.398095\n",
       "Name: Speed, dtype: float64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_data = trip_data[trip_data['Speed'] > 20]\n",
    "driving_data[driving_data['Speed'] > 100] = np.nan # invalid data\n",
    "avg_speed_by_day = pd.pivot_table(driving_data, values='Speed', index=['Day'], aggfunc=np.average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_lut = ['#7BBD32', '#F94117', '#00CCFF', '#235927', '#69A02B',\n",
    "             '#7BBD32', '#F94117', '#00CCFF', '#235927', '#69A02B',\n",
    "             '#7BBD32', '#F94117', '#00CCFF', '#235927', '#69A02B',\n",
    "             '#7BBD32', '#F94117', '#00CCFF', '#235927', '#69A02B']\n",
    "\n",
    "def feature_maker_from_pos(row): #lat, long, i\n",
    "    #print (row)\n",
    "    i = str(int(row.Row_Num) + 1)\n",
    "    if (row.Latitude is None or row.Longitude is None or \n",
    "        row.Latitude == np.nan or row.Longitude == np.nan): return \"\"\n",
    "    lat = float(\"{0:.6f}\".format(row.Latitude))\n",
    "    long = float(\"{0:.6f}\".format(row.Longitude))\n",
    "    color = color_lut[int(row.Day)]\n",
    "    \n",
    "    return {\"type\": \"Feature\", 'id': i, \"properties\": {\"marker-size\": \"small\",\n",
    "                                                       \"marker-symbol\": \"circle\",\n",
    "                                                       \"marker-color\": color},\n",
    "            \"geometry\": {\"type\": \"Point\",\"coordinates\": [long, lat]}}\n",
    "trip_data['Row_Num'] = list(range(len(trip_data)))\n",
    "trip_data_reduced = trip_data.dropna(subset=['Latitude','Longitude'],axis=0,how='all')\n",
    "features =[]\n",
    "for row in trip_data_reduced.itertuples():\n",
    "    features.append(feature_maker_from_pos(row))\n",
    "del trip_data_reduced\n",
    "del trip_data['Row_Num']\n",
    "# features = tr_d_df.apply(feature_maker_from_pos, axis=1)\n",
    "features = [str(x) for x in features]\n",
    "features_st = '{\"features\":['+','.join(features)+'],\"type\": \"FeatureCollection\"}'\n",
    "features_st = features_st.replace(\"\\'\", '\"')\n",
    "with open('trip_data.geojson', 'w') as f:\n",
    "    f.write(features_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mapbox import Static\n",
    "service = Static(access_token=mapbox_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt1 = {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {\"marker-size\": \"small\",\n",
    "                     \"marker-symbol\": \"circle\",\n",
    "                     \"marker-color\": \"#000000\"},\n",
    "      \"geometry\": {\n",
    "        \"type\": \"Point\",\n",
    "        \"coordinates\": [-86.7507626, 33.5480477]\n",
    "      }\n",
    "    }\n",
    "pt2 = {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {\"marker-size\": \"small\",\n",
    "                     \"marker-symbol\": \"circle\",\n",
    "                     \"marker-color\": \"#000000\"},\n",
    "      \"geometry\": {\n",
    "        \"type\": \"Point\",\n",
    "        \"coordinates\": [-87.2038367, 33.7517015]\n",
    "      }\n",
    "    }\n",
    "pt3 = {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {\"marker-size\": \"small\",\n",
    "                     \"marker-symbol\": \"circle\",\n",
    "                     \"marker-color\": \"#000000\"},\n",
    "      \"geometry\": {\n",
    "        \"type\": \"Point\",\n",
    "        \"coordinates\": [-88.3600413, 34.2431618]\n",
    "      }\n",
    "    }\n",
    "\n",
    "\n",
    "response = service.image('mapbox.streets', features=[pt1,pt2,pt3],width=1028, height=1028, image_format='png')\n",
    "print (response.url)\n",
    "with open('map.png', 'wb') as output:\n",
    "    _ = output.write(response.content)\n",
    "    \n",
    "#Next, try this: \n",
    "# Path\n",
    "\n",
    "# path-{strokecolor}-{strokeopacity}+{fillcolor}-{fillopacity}({polyline})\n",
    "# Encoded polylines with a precision of 5 decimal places can be used with the Static API via the path paramet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#_p~iF~ps|U_ulLnnqC_mqNvxq`@\n",
    "\n",
    "#path does not work with the sdk\n",
    "#but, this works....\n",
    "#https://api.mapbox.com/v4/mapbox.streets/path-5+f44-0.5+f44-0.2(kumwFrjvbMaf%40kuD%7BnCkS)/\n",
    "#-73.99,40.70,12/500x300.png?access_token={token}\n",
    "\n",
    "path-{strokecolor}-{strokeopacity}+{fillcolor}-{fillopacity}({polyline})\n",
    "\n",
    "\n",
    "\n",
    "response = service.image('mapbox.streets', \n",
    "                         features=[\"_p~iF~ps|U_ulLnnqC_mqNvxq`@\"],\n",
    "                         width=1028, height=1028, image_format='png')\n",
    "print (response.url)\n",
    "with open('map2.png', 'wb') as output:\n",
    "    _ = output.write(response.content)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import polyline\n",
    "pl = polyline.encode([(34.2431618, -88.3600413), (34.6226575, -89.204821), (36.499422, -91.537299)], 5)\n",
    "base = \"https://api.mapbox.com/v4/mapbox.streets\"\n",
    "path = \"path-5+f44-0.5+f44-0.2({})\".format(pl)\n",
    "center = \"-120.9,38.5\"\n",
    "zoom = \"12\"\n",
    "url = \"{}/{}/auto/500x300.png?access_token={}\".format(base, path, mapbox_token)\n",
    "print (url)\n",
    "response = requests.get(url, stream=True)\n",
    "with open('img.png', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "del response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mapbox import Datasets\n",
    "datasets = Datasets(access_token=mapbox_token)\n",
    "my_dataset = datasets.create(name='jhs_route66', description='Points along route taken on JHS cross-country jaunt')\n",
    "dataset_id = my_dataset.json()['id']\n",
    "print (my_dataset.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hourly_summary['cntr'] = range(len(hourly_summary))\n",
    "# features = hourly_summary.apply(feature_maker_from_pos, counter = 0, axis=1)\n",
    "\n",
    "trip_data_trim['cntr'] = range(len(trip_data_trim))\n",
    "features = trip_data_trim.apply(feature_maker_from_pos, axis=1)\n",
    "\n",
    "import time\n",
    "for f in list(features):\n",
    "    status = 0\n",
    "    while status == 200:\n",
    "        resp = datasets.batch_update_features(dataset_id, put=[f])\n",
    "        status = resp.status_code\n",
    "        if status != 200:\n",
    "            print (status)\n",
    "            time.sleep(2)\n",
    "\n",
    "print (my_dataset.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path-{strokecolor}-{strokeopacity}+{fillcolor}-{fillopacity}({polyline})\n",
    "\n",
    "\n",
    "\n",
    "response = service.image('mapbox.streets', features=[\"_p~iF~ps|U_ulLnnqC_mqNvxq`@\"],width=1028, height=1028, image_format='png')\n",
    "print (response.url)\n",
    "with open('map2.png', 'wb') as output:\n",
    "    _ = output.write(response.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collection = datasets.list_features(dataset_id).json()\n",
    "print(len(collection['features']))\n",
    "print ([f['id'] for f in collection['features']])\n",
    "# first = collection['features'][0]\n",
    "# print(first['id'])\n",
    "# print(first['properties']['name'])\n",
    "# print (resp.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len([ds for ds in datasets.list().json()]))\n",
    "for ds in datasets.list().json():\n",
    "    id_ = ds['id']\n",
    "    print (ds['name'])\n",
    "    print (id_)\n",
    "    r = datasets.delete_dataset(id_)\n",
    "    print (r.url)\n",
    "    print (r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The Google Maps Roads API takes up to 100 GPS points collected along a route, \n",
    "# and returns a similar set of data, with the points snapped to the most likely \n",
    "# roads the vehicle was traveling along. Optionally, you can request that the \n",
    "# points be interpolated, resulting in a path that smoothly follows the geometry of the road.\n",
    "\n",
    "#https://developers.google.com/maps/documentation/roads/nearest\n",
    "#https://developers.google.com/maps/documentation/roads/snap   \n",
    "#https://developer.here.com/platform-extensions/documentation/route-match/topics/quick-start.html\n",
    "\n",
    "import requests\n",
    "\n",
    "# if speed > 10\n",
    "# iterate over file and find sections of speed > 10\n",
    "#      gather contiguous points (at least 2, up to 100)\n",
    "# send points to API\n",
    "\n",
    "https://roads.googleapis.com/v1/snapToRoads?parameters&key=YOUR_API_KEY\n",
    "path=60.170880,24.942795|60.170879,24.942796|60.170877,24.942796\n",
    "\n",
    "https://roads.googleapis.com/v1/snapToRoads?path=-35.27801,149.12958|-35.28032,149.12907|-35.28099,149.12929\n",
    "    |-35.28144,149.12984|-35.28194,149.13003|-35.28282,149.12956|-35.28302,149.12881\n",
    "    |-35.28473,149.12836&interpolate=true&key=YOUR_API_KEY\n",
    "\n",
    "https://roads.googleapis.com/v1/snapToRoads?path=34.3325575,-88.8210022|34.3360208,-88.8246691&interpolate=true&\n",
    "    key=AIzaSyC92G3JW4JqVgaIWqO1DBFHhjKT2Z52114"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
